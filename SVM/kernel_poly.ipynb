{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "vVgTm86g1Bj1",
        "outputId": "9262b9ad-e395-49a9-9124-86fee2b1e0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   label      f1      f2       f3      f4      f5      f6      f7      f8  \\\n",
            "0      1 -13.559 -21.407 -11.4040 -15.248 -11.923 -15.291 -2.1548 -7.8474   \n",
            "1      1 -12.802 -20.335 -10.3990 -14.132 -11.096 -14.361 -2.4039 -7.5330   \n",
            "2      1 -12.431 -19.902 -10.0740 -13.598 -10.829 -14.048 -2.3566 -7.4717   \n",
            "3      1 -12.689 -19.529 -10.0280 -13.350 -11.056 -14.014 -2.6611 -6.8396   \n",
            "4      1 -12.686 -19.278  -9.8185 -13.108 -10.932 -13.939 -2.8675 -6.5919   \n",
            "\n",
            "        f9  ...     f165     f166    f167      f168     f169     f170  \\\n",
            "0 -10.0020  ...  0.18519  0.72602  5.3333  6.000000  0.29489  9.77780   \n",
            "1  -9.9369  ...  0.33333 -0.48751  2.1111  0.098765  0.83333  0.33333   \n",
            "2  -9.8283  ...  0.25926  0.25298  2.2222  0.172840  0.68889  0.88889   \n",
            "3  -9.5006  ...  0.16049  0.43750  4.1111  0.320990  0.83333  0.33333   \n",
            "4  -9.4594  ...  0.18519  0.35000  4.0000  0.444440  0.68889  0.88889   \n",
            "\n",
            "      f171     f172     f173     f174  \n",
            "0  2.44440  1.67700  0.20988  0.65422  \n",
            "1  0.33333  0.84869  0.50617 -0.18898  \n",
            "2  0.66667  1.27300  0.30864  0.10483  \n",
            "3  0.33333  1.14910  0.38272  0.41603  \n",
            "4  0.66667  1.58110  0.20988  0.50000  \n",
            "\n",
            "[5 rows x 175 columns]\n",
            "               label             f1             f2             f3  \\\n",
            "count  325834.000000  325834.000000  325834.000000  325834.000000   \n",
            "mean        4.062421     -15.143602     -24.026035     -15.400034   \n",
            "std         1.604617       3.504255       4.054214       3.267857   \n",
            "min         1.000000     -23.971000     -34.308000     -23.161000   \n",
            "25%         3.000000     -17.848000     -27.119000     -17.563000   \n",
            "50%         4.000000     -15.992000     -25.064000     -16.164000   \n",
            "75%         6.000000     -11.786000     -20.387000     -13.427000   \n",
            "max         7.000000       2.535600      -7.589100       1.104000   \n",
            "\n",
            "                 f4             f5             f6             f7  \\\n",
            "count  325834.00000  325834.000000  325834.000000  325834.000000   \n",
            "mean      -18.59383     -14.493472     -18.427329       0.256432   \n",
            "std         3.71163       3.189013       3.675741       1.682060   \n",
            "min       -27.24500     -22.103000     -26.897000      -5.582600   \n",
            "25%       -21.44900     -16.989000     -21.450000      -1.037800   \n",
            "50%       -19.58800     -15.099000     -19.282000       0.309180   \n",
            "75%       -15.65000     -11.735000     -15.514000       1.558200   \n",
            "max         0.77491      -0.887390       0.951780       7.029900   \n",
            "\n",
            "                  f8             f9  ...           f165           f166  \\\n",
            "count  325834.000000  325834.000000  ...  325834.000000  325834.000000   \n",
            "mean       -8.882434      -8.626002  ...       0.433834       0.329085   \n",
            "std         1.204040       2.002658  ...       0.245857       0.442008   \n",
            "min       -16.389000     -16.558000  ...       0.111110      -1.000000   \n",
            "25%        -9.658500     -10.070000  ...       0.259260       0.000000   \n",
            "50%        -8.915900      -8.733100  ...       0.358020       0.357140   \n",
            "75%        -8.190200      -7.158100  ...       0.506170       0.661440   \n",
            "max        -1.175400      -0.924610  ...       1.000000       1.000000   \n",
            "\n",
            "                f167           f168           f169           f170  \\\n",
            "count  325834.000000  325834.000000  325834.000000  325834.000000   \n",
            "mean        2.171177       0.080138       0.919604       0.174447   \n",
            "std         1.284653       0.182628       0.105953       0.373726   \n",
            "min         0.000000       0.000000       0.106190       0.000000   \n",
            "25%         1.000000       0.000000       0.833330       0.000000   \n",
            "50%         2.000000       0.000000       1.000000       0.000000   \n",
            "75%         3.000000       0.172840       1.000000       0.333330   \n",
            "max        12.444000      25.951000       1.000000      66.667000   \n",
            "\n",
            "                f171           f172           f173           f174  \n",
            "count  325834.000000  325834.000000  325834.000000  325834.000000  \n",
            "mean        0.162900       0.403288       0.764646       0.667567  \n",
            "std         0.222008       0.480141       0.273847       0.471260  \n",
            "min         0.000000      -0.000000       0.111110      -1.000000  \n",
            "25%         0.000000       0.000000       0.506170       0.357140  \n",
            "50%         0.000000      -0.000000       1.000000       1.000000  \n",
            "75%         0.333330       0.848690       1.000000       1.000000  \n",
            "max         6.666700       2.197200       1.000000       1.000000  \n",
            "\n",
            "[8 rows x 175 columns]\n",
            "Highly correlated pairs:\n",
            "('f1', 'f2')\n",
            "('f1', 'f5')\n",
            "('f1', 'f37')\n",
            "('f1', 'f39')\n",
            "('f2', 'f39')\n",
            "('f4', 'f6')\n",
            "('f4', 'f38')\n",
            "('f4', 'f41')\n",
            "('f5', 'f37')\n",
            "('f5', 'f40')\n",
            "('f6', 'f38')\n",
            "('f6', 'f41')\n",
            "('f7', 'f13')\n",
            "('f7', 'f15')\n",
            "('f11', 'f16')\n",
            "('f11', 'f17')\n",
            "('f11', 'f30')\n",
            "('f12', 'f17')\n",
            "('f12', 'f18')\n",
            "('f12', 'f30')\n",
            "('f13', 'f15')\n",
            "('f17', 'f30')\n",
            "('f27', 'f45')\n",
            "('f27', 'f49')\n",
            "('f29', 'f32')\n",
            "('f32', 'f36')\n",
            "('f33', 'f35')\n",
            "('f35', 'f36')\n",
            "('f37', 'f40')\n",
            "('f38', 'f41')\n",
            "('f43', 'f46')\n",
            "('f44', 'f47')\n",
            "('f45', 'f49')\n",
            "('f50', 'f53')\n",
            "('f50', 'f54')\n",
            "('f50', 'f55')\n",
            "('f50', 'f86')\n",
            "('f50', 'f87')\n",
            "('f51', 'f88')\n",
            "('f53', 'f54')\n",
            "('f53', 'f55')\n",
            "('f53', 'f86')\n",
            "('f53', 'f87')\n",
            "('f53', 'f90')\n",
            "('f54', 'f55')\n",
            "('f54', 'f86')\n",
            "('f54', 'f87')\n",
            "('f54', 'f89')\n",
            "('f54', 'f90')\n",
            "('f55', 'f86')\n",
            "('f55', 'f87')\n",
            "('f55', 'f90')\n",
            "('f56', 'f62')\n",
            "('f56', 'f64')\n",
            "('f56', 'f79')\n",
            "('f60', 'f65')\n",
            "('f60', 'f66')\n",
            "('f61', 'f66')\n",
            "('f61', 'f67')\n",
            "('f62', 'f64')\n",
            "('f62', 'f79')\n",
            "('f63', 'f84')\n",
            "('f63', 'f85')\n",
            "('f64', 'f79')\n",
            "('f74', 'f95')\n",
            "('f76', 'f94')\n",
            "('f76', 'f98')\n",
            "('f78', 'f81')\n",
            "('f81', 'f85')\n",
            "('f82', 'f84')\n",
            "('f84', 'f85')\n",
            "('f86', 'f87')\n",
            "('f86', 'f89')\n",
            "('f86', 'f90')\n",
            "('f87', 'f90')\n",
            "('f89', 'f90')\n",
            "('f89', 'f92')\n",
            "('f89', 'f95')\n",
            "('f92', 'f95')\n",
            "('f93', 'f96')\n",
            "('f94', 'f98')\n",
            "('f100', 'f102')\n",
            "('f101', 'f129')\n",
            "('f103', 'f121')\n",
            "('f104', 'f108')\n",
            "('f104', 'f111')\n",
            "('f105', 'f120')\n",
            "('f107', 'f109')\n",
            "('f107', 'f112')\n",
            "('f107', 'f116')\n",
            "('f108', 'f111')\n",
            "('f108', 'f117')\n",
            "('f109', 'f112')\n",
            "('f109', 'f116')\n",
            "('f111', 'f113')\n",
            "('f113', 'f114')\n",
            "('f118', 'f120')\n",
            "('f126', 'f127')\n",
            "('f131', 'f133')\n",
            "('f134', 'f135')\n",
            "('f139', 'f146')\n",
            "('f141', 'f159')\n",
            "('f142', 'f147')\n",
            "('f142', 'f149')\n",
            "('f143', 'f149')\n",
            "('f144', 'f148')\n",
            "('f147', 'f149')\n",
            "('f149', 'f154')\n",
            "('f151', 'f152')\n",
            "('f151', 'f153')\n",
            "('f152', 'f153')\n",
            "('f155', 'f156')\n",
            "('f155', 'f158')\n",
            "('f156', 'f157')\n",
            "('f164', 'f165')\n",
            "('f169', 'f171')\n",
            "('f172', 'f173')\n",
            "Features to remove:\n",
            "{'f54', 'f96', 'f2', 'f46', 'f147', 'f36', 'f98', 'f156', 'f146', 'f40', 'f47', 'f111', 'f157', 'f67', 'f159', 'f165', 'f152', 'f108', 'f38', 'f127', 'f92', 'f153', 'f35', 'f171', 'f18', 'f85', 'f32', 'f13', 'f86', 'f87', 'f62', 'f16', 'f39', 'f81', 'f84', 'f94', 'f112', 'f41', 'f133', 'f5', 'f49', 'f148', 'f102', 'f89', 'f17', 'f66', 'f135', 'f173', 'f15', 'f121', 'f154', 'f120', 'f88', 'f158', 'f6', 'f117', 'f65', 'f79', 'f45', 'f116', 'f113', 'f149', 'f55', 'f64', 'f129', 'f37', 'f114', 'f109', 'f30', 'f90', 'f53', 'f95'}\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-70cf84863af4>\u001b[0m in \u001b[0;36m<cell line: 48>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'poly'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m \u001b[0mclassifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;31m# Evaluate the SVM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"i\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_status_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m         \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibsvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "dataset = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/WinnipegDataset.txt')\n",
        "print(dataset.head())\n",
        "print(dataset.describe())\n",
        "\n",
        "# Calculate the correlation matrix\n",
        "correlation_matrix = dataset.corr()\n",
        "\n",
        "# Find columns that exceed the threshold\n",
        "high_corr = np.where(abs(correlation_matrix) > 0.95)\n",
        "high_corr_pairs = [(correlation_matrix.columns[x], correlation_matrix.columns[y]) for x, y in zip(*high_corr) if x != y and x < y]\n",
        "\n",
        "# Print the highly correlated pairs\n",
        "print(\"Highly correlated pairs:\")\n",
        "for pair in high_corr_pairs:\n",
        "    print(pair)\n",
        "\n",
        "# Choose one feature from each pair to remove\n",
        "features_to_remove = set([pair[1] for pair in high_corr_pairs])\n",
        "print(\"Features to remove:\")\n",
        "print(features_to_remove)\n",
        "\n",
        "# Drop the highly correlated features\n",
        "dataset = dataset.drop(columns=list(features_to_remove))\n",
        "\n",
        "# Split the dataset\n",
        "X = dataset.iloc[:, 1:].values\n",
        "y = dataset.iloc[:, 0].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\n",
        "\n",
        "# Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train the SVM\n",
        "from sklearn.svm import SVC\n",
        "svm_classifier = SVC(kernel = 'poly', random_state = 0)\n",
        "svm_classifier.fit(X_train_scaled, y_train)\n",
        "\n",
        "# Evaluate the SVM\n",
        "y_pred = svm_classifier.predict(X_test_scaled)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy}')\n",
        "\n",
        "# Generating the confusion matrix\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(cm)"
      ]
    }
  ]
}